{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4453318c-3fa5-4b1e-86d1-af7ec9ef15a0",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:01.190822Z",
     "iopub.status.busy": "2024-02-19T22:35:01.190669Z",
     "iopub.status.idle": "2024-02-19T22:35:05.886132Z",
     "shell.execute_reply": "2024-02-19T22:35:05.885570Z",
     "shell.execute_reply.started": "2024-02-19T22:35:01.190808Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./env/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./env/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./env/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./env/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: datasets in ./env/lib/python3.10/site-packages (2.17.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./env/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./env/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./env/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./env/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./env/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./env/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./env/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: accelerate in ./env/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in ./env/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in ./env/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./env/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in ./env/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./env/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (65.5.0)\n",
      "Requirement already satisfied: wheel in ./env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.42.0)\n",
      "Requirement already satisfied: cmake in ./env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.28.3)\n",
      "Requirement already satisfied: lit in ./env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install datasets\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f3a7cc-f23a-43fd-8f29-050ddc6bf431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:46.545695Z",
     "iopub.status.busy": "2024-02-19T23:04:46.545538Z",
     "iopub.status.idle": "2024-02-19T23:04:46.559425Z",
     "shell.execute_reply": "2024-02-19T23:04:46.559017Z",
     "shell.execute_reply.started": "2024-02-19T23:04:46.545676Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e90f14-a776-47b2-9265-ff4fb8689608",
   "metadata": {},
   "source": [
    "> this notebook will follow the tutorial in:\n",
    "https://blog.gopenai.com/fine-tuning-dialogpt-medium-on-daily-dialog-dataset-a-step-by-step-guide-4eaecc1b9323"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a8aa2-047a-43ae-bcde-56e23f48c6c9",
   "metadata": {},
   "source": [
    "# make my own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f0a4b1-a071-446a-8fb9-2604542b6447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:52.001919Z",
     "iopub.status.busy": "2024-02-19T23:04:52.001446Z",
     "iopub.status.idle": "2024-02-19T23:04:52.008268Z",
     "shell.execute_reply": "2024-02-19T23:04:52.007887Z",
     "shell.execute_reply.started": "2024-02-19T23:04:52.001901Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/learn/nlp-course/chapter5/5\n",
    "# https://huggingface.co/learn/nlp-course/chapter5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5eb83a7-2330-46ad-a22f-a80cca669419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:52.513546Z",
     "iopub.status.busy": "2024-02-19T23:04:52.513005Z",
     "iopub.status.idle": "2024-02-19T23:04:53.035979Z",
     "shell.execute_reply": "2024-02-19T23:04:53.035365Z",
     "shell.execute_reply.started": "2024-02-19T23:04:52.513520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92d28bf-d212-464e-a7c1-31d181ddf324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:53.036826Z",
     "iopub.status.busy": "2024-02-19T23:04:53.036630Z",
     "iopub.status.idle": "2024-02-19T23:04:53.049299Z",
     "shell.execute_reply": "2024-02-19T23:04:53.048718Z",
     "shell.execute_reply.started": "2024-02-19T23:04:53.036812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/dlr7_2016-m.json',\n",
       " 'data/DL103_2008.json',\n",
       " 'data/0331103315.json',\n",
       " 'data/DL320_2002.json',\n",
       " 'data/L65_2013.json',\n",
       " 'data/DLR4_2012_A.json',\n",
       " 'data/0288702916.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('data/*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ef9a0-624d-4557-83b1-2d77bf194189",
   "metadata": {},
   "source": [
    "we can also set the splits\n",
    "\n",
    "`data_files = {\"train\": \"json_example.json\", \"test\": \"json_example.json\"}`\n",
    "`dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a66f020-e58e-4f87-8c59-54c361828133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:55.738963Z",
     "iopub.status.busy": "2024-02-19T23:04:55.738746Z",
     "iopub.status.idle": "2024-02-19T23:04:56.671479Z",
     "shell.execute_reply": "2024-02-19T23:04:56.670792Z",
     "shell.execute_reply.started": "2024-02-19T23:04:55.738945Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=glob('data/*.json'))\n",
    "\n",
    "# train test split\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebcdf67-1352-46d6-a383-3fef1db122ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:57.321318Z",
     "iopub.status.busy": "2024-02-19T23:04:57.320571Z",
     "iopub.status.idle": "2024-02-19T23:04:57.334786Z",
     "shell.execute_reply": "2024-02-19T23:04:57.334315Z",
     "shell.execute_reply.started": "2024-02-19T23:04:57.321296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'page'],\n",
       "        num_rows: 84\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'page'],\n",
       "        num_rows: 22\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c149d2a5-a476-4cce-8c9a-114be87d2a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:58.257295Z",
     "iopub.status.busy": "2024-02-19T23:04:58.257010Z",
     "iopub.status.idle": "2024-02-19T23:04:58.272353Z",
     "shell.execute_reply": "2024-02-19T23:04:58.271930Z",
     "shell.execute_reply.started": "2024-02-19T23:04:58.257272Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Diário da República, 1.ª série — N.º 120 — 24 de Junho de 2008 1.2.4.3 — Paragem de emergência. — A máquina deve estar equipada com um ou vários dispositivos de paragem de emergência por meio do ou dos quais possam ser evita- das situações de perigo iminentes ou existentes',\n",
       "  'Estão excluídas desta obrigação: — As máquinas cujo dispositivo de paragem de emer- gência não permita reduzir o risco quer por não reduzir o tempo de obtenção da paragem normal quer por não per- mitir tomar as medidas específicas exigidas pelo risco; — As máquinas portáteis mantidas em posição e ou guiadas à mão',\n",
       "  'Este dispositivo deve: — Conter dispositivos de comando claramente identi- ficáveis, bem visíveis e rapidamente acessíveis; — Provocar a paragem do processo perigoso num período de tempo tão reduzido quanto possível sem provocar riscos suplementares; — Eventualmente desencadear, ou permitir desencadear, determinados movimentos de protecção',\n",
       "  'Quando se deixa de accionar o dispositivo de paragem de emergência depois de se ter dado uma ordem de para- gem, esta ordem deve ser mantida por um bloqueamento do dispositivo de paragem de emergência até ao respectivo desbloqueamento; não deve ser possível obter o bloquea- mento do dispositivo sem que este provoque uma ordem de paragem; o desbloqueamento do dispositivo só deve poder ser obtido através de uma manobra apropriada e não deve repor a máquina em funcionamento, mas somente autorizar um novo arranque',\n",
       "  'A função de paragem de emergência deve existir e estar operacional em todas as circunstâncias, independentemente do modo de funcionamento',\n",
       "  'Os dispositivos de paragem de emergência devem com- plementar outras medidas de protecção e não substituir- -se -lhes',\n",
       "  '1.2.4.4 — Conjuntos de máquinas. — As máquinas ou elementos de máquinas concebidos para trabalhar em conjunto devem ser concebidos e fabricados de modo a que os comandos de paragem, incluindo os dispositivos de paragem de emergência, possam parar não só a má- quina mas também todos os equipamentos associados se a sua manutenção em funcionamento puder constituir um perigo',\n",
       "  '1.2.5 — Selecção de modos de comando ou de funcionamento. — O modo de comando ou de funcio- namento seleccionado deve ter prioridade sobre todos os outros modos de comando ou de funcionamento, com excepção da paragem de emergência',\n",
       "  'Se a máquina tiver sido concebida e fabricada de modo a permitir a sua utilização segundo vários modos de comando ou de funcionamento que exijam medidas de protecção e ou processos de trabalho diferentes, deve ser equipada com um selector de modo bloqueável em cada posição',\n",
       "  'Cada posição do selector deve ser claramente identificá- vel e corresponder a um único modo de comando ou de funcionamento',\n",
       "  'O selector pode ser substituído por outros meios de se- lecção que permitam limitar a utilização de determinadas funções da máquina a certas categorias de operadores',\n",
       "  'Se, para certas operações, a máquina deve poder fun- cionar com um protector deslocado ou retirado e ou com um dispositivo de protecção neutralizado, o selector de',\n",
       "  '3774 D Se nenhuma destas possibilidades for aplicável, deverá, antes do arranque da máquina, ser dado um sinal de aviso, sonoro e ou visual. As pessoas expostas devem ter tempo para abandonar a zona perigosa ou para se opor ao arran- que da máquina',\n",
       "  'Se necessário, a máquina deverá dispor de meios para que só possa ser comandada a partir de postos de comando situados numa ou em várias zonas ou localizações prede- terminadas',\n",
       "  'Caso haja vários postos de comando, o sistema de co- mando deve ser concebido de modo a que a utilização de um deles torne impossível a utilização dos outros, com excepção dos dispositivos de paragem e de paragem de emergência',\n",
       "  'Quando uma máquina tiver dois ou mais postos de tra- balho, cada um deles deve dispor de todos os dispositivos de comando necessários de modo a que nenhum dos ope- radores possa perturbar ou colocar os outros em situação perigosa',\n",
       "  '1.2.3 — Arranque. — O arranque de uma máquina só deve poder ser efectuado por acção voluntária sobre um dispositivo de comando previsto para o efeito',\n",
       "  'O mesmo se deve verificar: — Para o novo arranque após uma paragem, seja qual for a sua origem; — Para o comando de uma alteração importante das condições de funcionamento',\n",
       "  'No entanto, o novo arranque ou a alteração das condi- ções de funcionamento podem ser efectuados por acção voluntária sobre um dispositivo diferente do dispositivo de comando previsto para o efeito desde que tal não conduza a uma situação perigosa',\n",
       "  'Em relação a máquinas que funcionam automatica- mente, o arranque, o novo arranque depois de uma paragem ou a alteração das condições de funcionamento podem produzir -se sem intervenção desde que tal não conduza a uma situação perigosa',\n",
       "  'Sempre que a máquina disponha de vários dispositivos de comando de arranque e os operadores possam, por conseguinte, colocar -se mutuamente em perigo, deve estar equipada com dispositivos adicionais para eliminar esse risco. Se, por uma questão de segurança, o arranque e ou a paragem tiverem de obedecer a uma dada sequência, deverão ser previstos dispositivos que garantam que essas operações são executadas na sequência correcta',\n",
       "  '1.2.4 — Paragem: 1.2.4.1 — Paragem normal. — A máquina deve estar equipada com um dispositivo de comando que permita a sua paragem total em condições de segurança',\n",
       "  'Cada posto de trabalho deve estar equipado com um dis- positivo de comando que permita, em função dos perigos existentes, parar todas as funções da máquina ou apenas parte delas de modo a que a máquina esteja em situação de segurança',\n",
       "  'A ordem de paragem da máquina deve ter prioridade sobre as ordens de arranque',\n",
       "  'Uma vez obtida a paragem da máquina ou das suas funções perigosas, deve ser interrompida a alimentação de energia dos accionadores',\n",
       "  '1.2.4.2 — Paragem por razões operacionais. — Quando, por razões operacionais, seja necessário um comando de paragem que não interrompa a alimentação de energia dos accionadores, a função de paragem deve ser monitorizada e mantida.'],\n",
       " 'page': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff05d794-de18-4674-83bb-44c8d10d3c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:04:58.695583Z",
     "iopub.status.busy": "2024-02-19T23:04:58.695169Z",
     "iopub.status.idle": "2024-02-19T23:04:58.706737Z",
     "shell.execute_reply": "2024-02-19T23:04:58.706161Z",
     "shell.execute_reply.started": "2024-02-19T23:04:58.695564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate all utterances within a dialogue and map to 'dialog' key\n",
    "def concatenate_paragraphs(example):\n",
    "    example['page'] = \" \".join(example['text'])\n",
    "    return example\n",
    "\n",
    "# dataset = dataset.map(concatenate_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb19276-8bd1-472d-b254-639882c4d365",
   "metadata": {},
   "source": [
    "> Note: not sure if this is really needed, but for simplicity will make a whole text per example\n",
    ">\n",
    "> The DialogPT is based on short context, this doesn't lead to good results! Will be trying without concatenating as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fd709e-7a50-46f5-a48d-3ca11bec411b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:05:00.644801Z",
     "iopub.status.busy": "2024-02-19T23:05:00.644518Z",
     "iopub.status.idle": "2024-02-19T23:05:00.674608Z",
     "shell.execute_reply": "2024-02-19T23:05:00.674145Z",
     "shell.execute_reply.started": "2024-02-19T23:05:00.644779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 9002.49 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 4977.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def flatten_list_of_dict(batch):\n",
    "    return {\"page\": [ex_string for ex_list in batch[\"text\"] for ex_string in ex_list]}\n",
    "\n",
    "dataset = dataset.map(flatten_list_of_dict, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e2b7af-030e-41b4-bc50-8920248106e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:05:02.485409Z",
     "iopub.status.busy": "2024-02-19T23:05:02.485183Z",
     "iopub.status.idle": "2024-02-19T23:05:02.550944Z",
     "shell.execute_reply": "2024-02-19T23:05:02.550498Z",
     "shell.execute_reply.started": "2024-02-19T23:05:02.485391Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████| 1485/1485 [00:00<00:00, 39928.08 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 367/367 [00:00<00:00, 36765.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# re-joining the words separated by \"-\"\n",
    "def text_processing(example):\n",
    "    example['page'] = example['page'].replace(\"- \", \"\")\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f66bb2-4027-4053-bd13-0215cea0bbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:05:32.354145Z",
     "iopub.status.busy": "2024-02-19T23:05:32.353953Z",
     "iopub.status.idle": "2024-02-19T23:05:32.368119Z",
     "shell.execute_reply": "2024-02-19T23:05:32.367676Z",
     "shell.execute_reply.started": "2024-02-19T23:05:32.354130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': ['Diário da República, 1.ª série — N.º 120 — 24 de Junho de 2008 1.2.4.3 — Paragem de emergência. — A máquina deve estar equipada com um ou vários dispositivos de paragem de emergência por meio do ou dos quais possam ser evitadas situações de perigo iminentes ou existentes',\n",
       "  'Estão excluídas desta obrigação: — As máquinas cujo dispositivo de paragem de emergência não permita reduzir o risco quer por não reduzir o tempo de obtenção da paragem normal quer por não permitir tomar as medidas específicas exigidas pelo risco; — As máquinas portáteis mantidas em posição e ou guiadas à mão',\n",
       "  'Este dispositivo deve: — Conter dispositivos de comando claramente identificáveis, bem visíveis e rapidamente acessíveis; — Provocar a paragem do processo perigoso num período de tempo tão reduzido quanto possível sem provocar riscos suplementares; — Eventualmente desencadear, ou permitir desencadear, determinados movimentos de protecção',\n",
       "  'Quando se deixa de accionar o dispositivo de paragem de emergência depois de se ter dado uma ordem de paragem, esta ordem deve ser mantida por um bloqueamento do dispositivo de paragem de emergência até ao respectivo desbloqueamento; não deve ser possível obter o bloqueamento do dispositivo sem que este provoque uma ordem de paragem; o desbloqueamento do dispositivo só deve poder ser obtido através de uma manobra apropriada e não deve repor a máquina em funcionamento, mas somente autorizar um novo arranque',\n",
       "  'A função de paragem de emergência deve existir e estar operacional em todas as circunstâncias, independentemente do modo de funcionamento',\n",
       "  'Os dispositivos de paragem de emergência devem complementar outras medidas de protecção e não substituir-se -lhes',\n",
       "  '1.2.4.4 — Conjuntos de máquinas. — As máquinas ou elementos de máquinas concebidos para trabalhar em conjunto devem ser concebidos e fabricados de modo a que os comandos de paragem, incluindo os dispositivos de paragem de emergência, possam parar não só a máquina mas também todos os equipamentos associados se a sua manutenção em funcionamento puder constituir um perigo',\n",
       "  '1.2.5 — Selecção de modos de comando ou de funcionamento. — O modo de comando ou de funcionamento seleccionado deve ter prioridade sobre todos os outros modos de comando ou de funcionamento, com excepção da paragem de emergência',\n",
       "  'Se a máquina tiver sido concebida e fabricada de modo a permitir a sua utilização segundo vários modos de comando ou de funcionamento que exijam medidas de protecção e ou processos de trabalho diferentes, deve ser equipada com um selector de modo bloqueável em cada posição',\n",
       "  'Cada posição do selector deve ser claramente identificável e corresponder a um único modo de comando ou de funcionamento']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d08da-201f-47a4-9e80-d99d8fe4ddae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DETOUR!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2f8d6e-733c-4051-9c61-0c567354faa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T20:41:58.161103Z",
     "iopub.status.busy": "2024-02-19T20:41:58.160719Z",
     "iopub.status.idle": "2024-02-19T20:41:58.176270Z",
     "shell.execute_reply": "2024-02-19T20:41:58.175595Z",
     "shell.execute_reply.started": "2024-02-19T20:41:58.161078Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5902f014-698e-41bc-86e6-afb0f094a498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T20:18:06.817723Z",
     "iopub.status.busy": "2024-02-19T20:18:06.817333Z",
     "iopub.status.idle": "2024-02-19T20:19:58.062024Z",
     "shell.execute_reply": "2024-02-19T20:19:58.061454Z",
     "shell.execute_reply.started": "2024-02-19T20:18:06.817698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./env/lib/python3.10/site-packages (from torch==2.0.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (65.5.0)\n",
      "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1)\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=3249284b82d28d23e7cecf4a8bc3f24e97db258f30bb14af7619eeb4961eaba5\n",
      "  Stored in directory: /home/ana/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, wheel, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed cmake-3.28.3 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0 wheel-0.42.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: FIX TORCH VERSION  -> this one was not the one original!!\n",
    "!pip3 install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71b8c4-f5fd-4e3f-aee1-32e84a432e4d",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55af3c70-e86f-4865-bc9b-49830c1d29d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:18.091107Z",
     "iopub.status.busy": "2024-02-19T22:35:18.090882Z",
     "iopub.status.idle": "2024-02-19T22:35:20.571854Z",
     "shell.execute_reply": "2024-02-19T22:35:20.571405Z",
     "shell.execute_reply.started": "2024-02-19T22:35:18.091091Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('microsoft/DialoGPT-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b777bdb8-7a90-4ac0-b985-6ce39d818ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:20.572783Z",
     "iopub.status.busy": "2024-02-19T22:35:20.572566Z",
     "iopub.status.idle": "2024-02-19T22:35:22.627456Z",
     "shell.execute_reply": "2024-02-19T22:35:22.627055Z",
     "shell.execute_reply.started": "2024-02-19T22:35:20.572769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████| 1477/1477 [00:00<00:00, 2606.05 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 2216.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the dataset\n",
    "# https://huggingface.co/docs/transformers/en/pad_truncation\n",
    "def encode(examples):\n",
    "    encoded = tokenizer(examples['page'],\n",
    "                        truncation=True, \n",
    "                        padding='max_length',\n",
    "                        max_length=128\n",
    "                       )\n",
    "    encoded['labels'] = encoded['input_ids'][:]\n",
    "\n",
    "    return encoded\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4190f6-3656-4781-a05f-a0fc5d401ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T22:46:09.102739Z",
     "iopub.status.busy": "2024-02-05T22:46:09.102005Z",
     "iopub.status.idle": "2024-02-05T22:46:09.143052Z",
     "shell.execute_reply": "2024-02-05T22:46:09.141608Z",
     "shell.execute_reply.started": "2024-02-05T22:46:09.102656Z"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa65fdb-9802-4f32-a248-8c1d82bf8720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:25.302964Z",
     "iopub.status.busy": "2024-02-19T22:35:25.302607Z",
     "iopub.status.idle": "2024-02-19T22:35:26.100367Z",
     "shell.execute_reply": "2024-02-19T22:35:26.099914Z",
     "shell.execute_reply.started": "2024-02-19T22:35:25.302948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=tempfile.mkdtemp(),   # output directory\n",
    "    num_train_epochs=25,             # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,                # directory for storing logs\n",
    "    fp16=True                        # use floating point 16 bit precision for training\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de615ecb-e60c-4388-808e-a672b0305fea",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b036b987-e794-41d1-b7ed-2cdb1a69a18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:26.937816Z",
     "iopub.status.busy": "2024-02-19T22:35:26.937242Z",
     "iopub.status.idle": "2024-02-19T22:35:29.134362Z",
     "shell.execute_reply": "2024-02-19T22:35:29.133874Z",
     "shell.execute_reply.started": "2024-02-19T22:35:26.937793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate before fine-tuning\n",
    "pre_eval_results = trainer.evaluate(encoded_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77244853-6b0e-4ef9-9df9-b1b54f33bc39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:29.135338Z",
     "iopub.status.busy": "2024-02-19T22:35:29.135205Z",
     "iopub.status.idle": "2024-02-19T22:35:29.278398Z",
     "shell.execute_reply": "2024-02-19T22:35:29.277796Z",
     "shell.execute_reply.started": "2024-02-19T22:35:29.135325Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46356329-c14a-474e-b854-3af16cf54049",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e73fc018-0493-4089-bc87-93fe375a2cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:29.782025Z",
     "iopub.status.busy": "2024-02-19T22:35:29.781393Z",
     "iopub.status.idle": "2024-02-19T22:46:54.521789Z",
     "shell.execute_reply": "2024-02-19T22:46:54.521403Z",
     "shell.execute_reply.started": "2024-02-19T22:35:29.782001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4625' max='4625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4625/4625 11:24, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.835400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4625, training_loss=1.423659377639358, metrics={'train_runtime': 684.5815, 'train_samples_per_second': 53.938, 'train_steps_per_second': 6.756, 'total_flos': 2412052070400000.0, 'train_loss': 1.423659377639358, 'epoch': 25.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e04eb3-2e2d-486e-8910-4ec87c3eaf7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:56:01.859308Z",
     "iopub.status.busy": "2024-02-19T22:56:01.859059Z",
     "iopub.status.idle": "2024-02-19T22:56:03.807036Z",
     "shell.execute_reply": "2024-02-19T22:56:03.806641Z",
     "shell.execute_reply.started": "2024-02-19T22:56:01.859292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results before fine-tuning : 9.061310768127441\n",
      "Evaluation Results after fine-tuning  : 1.5355618000030518\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))\n",
    "# Evaluate after fine-tuning\n",
    "post_eval_results = trainer.evaluate(encoded_dataset['test'])\n",
    "\n",
    "# Print the evaluation losses before and after fine-tuning\n",
    "print('Evaluation Results before fine-tuning :', pre_eval_results['eval_loss'])\n",
    "print('Evaluation Results after fine-tuning  :', post_eval_results['eval_loss'])\n",
    "\n",
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "post_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))\n",
    "\n",
    "# Zip the pre and post tuning predictions\n",
    "predictions = zip(pre_val_predictions.predictions, post_val_predictions.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aceb47-b8c8-4437-8f51-2cea2d490e01",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4579fed6-e435-42c3-8eb2-ddd436a0852b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:56:34.854727Z",
     "iopub.status.busy": "2024-02-19T22:56:34.854529Z",
     "iopub.status.idle": "2024-02-19T22:56:34.925117Z",
     "shell.execute_reply": "2024-02-19T22:56:34.924596Z",
     "shell.execute_reply.started": "2024-02-19T22:56:34.854713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth 0 \n",
      "DAREPÚBLICA—ISÉRIE-A 8161 d) Empresa de manutenção de ascensores (EMA) a entidadequeefectuaeéresponsávelpelamanu- tenção das instalações, cujo estatuto constitui o anexo I a este diploma e que dele faz parte integrante; e) Entidade inspectora (EI) a empresa habilitada a efectuar inspecções a instalações, bem como a realizar inquéritos, peritagens, relatórios e pareceres, cujo estatuto constitui o anexo IV a este diploma e que dele faz parte integrante\n",
      "\n",
      "Pre-prediction \n",
      " —EPÚBLICA—ISÉRIE-A 8165 8) Apresresa de manutenção de ascensores,M) 1)idade gest souncuar)cnabilvel posutenêsehaã,as Ealações o porjo ascatuto dui- proprietexo IV aoja, que se faz parte integrante; e) Emidade queore deEMAI), eopresa dejailitar;ofetuar;petção�es peroalações, om\n",
      "\n",
      "Post-prediction \n",
      " —EPÚBLICA—ISÉRIE-A 8165 8) Apresresa de manutenção de ascensores,M) 1)idade gest souncuar)cnabilvel posutenêsehaã,as Ealações o porjo ascatuto dui- proprietexo IV aoja, que se faz parte integrante; e) Emidade queore deEMAI), eopresa dejailitar;ofetuar;petção�es peroalações, om\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 1 \n",
      "CAPÍTULOII Manutenção Artigo3.o Obrigaçãodemanutenção 1—Asinstalaçõesabrangidaspelopresentediploma ficam,obrigatoriamente,sujeitasamanutençãoregular, a qual é assegurada por uma EMA, que assumirá a responsabilidade, criminal e civil, pelos acidentes cau- sados pela deficiente manutenção das instalações ou peloincumprimentodasnormasaplicáveis\n",
      "\n",
      "Pre-prediction \n",
      " —TULO II Disutenção Artigo15.o Competbrigaç�odeasutenção 1—Asinsalaçõesderasidoseloprediploma,icaam obnomrigatoriamente,djeitas-utençãocom-ist,secompan de assegurada por uma EMA, a deleirá a responsabilidade do pel o criminal, pelo acidentes causumpç ros daela Ee manutenção deas instalações abu,as instarcerrimentoesemaninst\n",
      "\n",
      "Post-prediction \n",
      " —TULO II Disutenção Artigo15.o Competbrigaç�odeasutenção 1—Asinsalaçõesderasidoseloprediploma,icaam obnomrigatoriamente,djeitas-utençãocom-ist,secompan de assegurada por uma EMA, a deleirá a responsabilidade do pel o criminal, pelo acidentes causumpç ros daela Ee manutenção deas instalações abu,as instarcerrimentoesemaninst\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 2 \n",
      "2—O proprietário da instalação é responsável soli- dariamente, nos termos do número anterior, sem pre- juízo da transferência da responsabilidade para uma entidadeseguradora\n",
      "\n",
      "Pre-prediction \n",
      " —A prodário da instalação é responsável peli- daráente, por termos da número anterior, os preju vízo da instência da atabilidade civil ama Eidade insuranantora\n",
      "\n",
      "Post-prediction \n",
      " —A prodário da instalação é responsável peli- daráente, por termos da número anterior, os preju vízo da instência da atabilidade civil ama Eidade insuranantora\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 3 \n",
      "3—Paraefeitosderesponsabilidadecriminaloucivil, presume-se que os contratos de manutenção a que res- peita o artigo seguinte integram sempre os requisitos mínimos estabelecidos para o respectivo tipo, estabe- lecidosnoartigo5.o 4—A EMA tem o dever de informar por escrito o proprietário das reparações que se torne necessário efectuar\n",
      "\n",
      "Pre-prediction \n",
      " —Osara eitosnveabilidadecivil,a,se - pl que os protectatos de manutenção de que sepe pita a contrigo seguinte:ram sempre os requisitos deínimos estabelecidos no o artivo contro de aele- cceridos noartigo12.o —O EMA de o tipver de informar o entrito, proprietário,as instarações, sejamne aário,fetuar\n",
      "\n",
      "Post-prediction \n",
      " —Osara eitosnveabilidadecivil,a,se - pl que os protectatos de manutenção de que sepe pita a contrigo seguinte:ram sempre os requisitos deínimos estabelecidos no o artivo contro de aele- cceridos noartigo12.o —O EMA de o tipver de informar o entrito, proprietário,as instarações, sejamne aário,fetuar\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 4 \n",
      "5—Caso sejadetectadasituaçãodegraveriscopara o funcionamento da instalação, a EMA deve proceder àsuaimediataimobilização,dandodissoconhecimento, por escrito, ao proprietário e à câmara municipal res- pectiva,noprazodequarentaeoitohoras\n",
      "\n",
      "Pre-prediction \n",
      " —Oso disjaasáu comadosopãodinsuniáosréçuionamento da malação, o EMA deve serer à suaaplomaservizaçãoseeverereecocstrucimentocdobrito, noo proprietário e a DGâmara municipal competentpe ponsados aomeresentodeelementalidificquividosp-\n",
      "\n",
      "Post-prediction \n",
      " —Oso disjaasáu comadosopãodinsuniáosréçuionamento da malação, o EMA deve serer à suaaplomaservizaçãoseeverereecocstrucimentocdobrito, noo proprietário e a DGâmara municipal competentpe ponsados aomeresentodeelementalidificquividosp-\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 5 \n",
      "Artigo4.o Contratodemanutenção 1—O proprietário de uma instalação em serviço é obrigado a celebrar um contrato de manutenção com umaEMA\n",
      "\n",
      "Pre-prediction \n",
      "igo 5.o Distrodemanutenção 1—Ocontário d uma instalação, serviço d obrigat a instar um contrato de manutenção a uma E\n",
      "\n",
      "Post-prediction \n",
      "igo 5.o Distrodemanutenção 1—Ocontário d uma instalação, serviço d obrigat a instar um contrato de manutenção a uma E\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 6 \n",
      "2—O contrato de manutenção, no caso de insta- lações novas, deverá iniciar a sua vigência no momento da entrada em serviço da instalação, sem prejuízo do dispostononúmeroseguinte\n",
      "\n",
      "Pre-prediction \n",
      " —A prodato de manutenção sim a caso de manala- lações,vas, beverá sericiar a sua vigência, momento da entrada em serviço da instalação, oprejuízo da dispostoibrioolevinte:\n",
      "\n",
      "Post-prediction \n",
      " —A prodato de manutenção sim a caso de manala- lações,vas, beverá sericiar a sua vigência, momento da entrada em serviço da instalação, oprejuízo da dispostoibrioolevinte:\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 7 \n",
      "3—Durante o primeiro ano de funcionamento da instalação, a entidade instaladora fica obrigada, direc- tamente ou através de uma EMA, a assegurar a sua manutenção,salvoseoproprietárioadesobrigar,através da celebração de um contrato de manutenção com umaEMA\n",
      "\n",
      "Pre-prediction \n",
      " —Osante asuiro apo a instionamento da instalação, o entidade gestaladora fica obrigada, peltç mentamente ou retravés de umma EMI, a entsegurar que sua imutenção, avoigormbresentetárioosminist-rigatorseravésd instração de u anato de manutenção, uma E,\n",
      "\n",
      "Post-prediction \n",
      " —Osante asuiro apo a instionamento da instalação, o entidade gestaladora fica obrigada, peltç mentamente ou retravés de umma EMI, a entsegurar que sua imutenção, avoigormbresentetárioosminist-rigatorseravésd instração de u anato de manutenção, uma E,\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 8 \n",
      "Artigo5.o Tiposdecontratodemanutenção 1—O contrato de manutenção, a estabelecer entre o proprietário de uma instalação e uma EMA, pode corresponderaumdosseguintestipos: a) Contrato de manutenção simples, destinado a manterainstalaçãoemboascondiçõesdesegu-\n",
      "\n",
      "Pre-prediction \n",
      "igo 5.o Distosasontrolodemanutenção 1—Sem prodato de manutenção de a Eelecer entre o proprietário e uma Ealação e uma EMA, aode soliciter aainsseguintesipuld a) Erato de manutenção,ples, oinado a manter adaicção,penquesensição�es;egí l\n",
      "\n",
      "Post-prediction \n",
      "igo 5.o Distosasontrolodemanutenção 1—Sem prodato de manutenção de a Eelecer entre o proprietário e uma Ealação e uma EMA, aode soliciter aainsseguintesipuld a) Erato de manutenção,ples, oinado a manter adaicção,penquesensição�es;egí l\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 9 \n",
      "N.o300—28deDezembrode2002 DIÁRIOD Porseuturno,opresentediplomavisa,também,trans- ferir para as câmaras municipais a competência para o licenciamento e fiscalização destas instalações, até ao momentoatribuídaàsdirecçõesregionaisdeeconomia, em obediência à alínea a) do n.o 2 do artigo 17.o da Lei n.o 159/99, de 14 de Setembro, que estabelece o quadro de transferência de atribuições e competências paraasautarquiaslocais\n",
      "\n",
      "Pre-prediction \n",
      " —o300—28deDezembrode2002 DIÁRIOD ArtORiroodaDdresentediplomaaealiopseravém rsemiss missid o o pâmaras municipais,oência da a trenciamento da àização doin,alações, arav sero municipaloodouíd,sdaccção�esparais,veian esrig-ncia desínea a) do n.o 1 do artigo 4.º; Const n.o 433/\n",
      "\n",
      "Post-prediction \n",
      " —o300—28deDezembrode2002 DIÁRIOD ArtORiroodaDdresentediplomaaealiopseravém rsemiss missid o o pâmaras municipais,oência da a trenciamento da àização doin,alações, arav sero municipaloodouíd,sdaccção�esparais,veian esrig-ncia desínea a) do n.o 1 do artigo 4.º; Const n.o 433/\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (pre, post) in enumerate(predictions):\n",
    "    pre_pred = tokenizer.decode(np.argmax(pre, axis=-1), skip_special_tokens=True)\n",
    "    post_pred = tokenizer.decode(np.argmax(post, axis=-1), skip_special_tokens=True)\n",
    "    ground_truth = encoded_dataset['test'][idx][\"page\"]\n",
    "    \n",
    "    print(f'Ground truth {idx} \\n' + ground_truth + '\\n')\n",
    "    print('Pre-prediction \\n' + \"\".join(pre_pred) + '\\n')\n",
    "    print('Post-prediction \\n'+ \"\".join(post_pred) + '\\n')\n",
    "    print('----------------------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d8fa6-f3c5-46c6-8ab7-d970845a61f8",
   "metadata": {},
   "source": [
    "## GPT2 IN PORTUGUESpierreguillou/gpt2-small-portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb6ec5-081b-4951-82c9-a4413c62c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/pierreguillou/gpt2-small-portuguese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab2df8-50c0-44a7-a7e0-ff73587ee3dd",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3878a5d-20a9-4efb-9065-1b6db814b78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:06:35.685671Z",
     "iopub.status.busy": "2024-02-19T23:06:35.685177Z",
     "iopub.status.idle": "2024-02-19T23:06:54.321535Z",
     "shell.execute_reply": "2024-02-19T23:06:54.321049Z",
     "shell.execute_reply.started": "2024-02-19T23:06:35.685653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|████████████████████████████████████████████████████████████████████| 92.0/92.0 [00:00<00:00, 428kB/s]\n",
      "vocab.json: 100%|███████████████████████████████████████████████████████████████████████████████| 850k/850k [00:01<00:00, 583kB/s]\n",
      "merges.txt: 100%|███████████████████████████████████████████████████████████████████████████████| 508k/508k [00:00<00:00, 547kB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 761kB/s]\n",
      "config.json: 100%|███████████████████████████████████████████████████████████████████████████████| 666/666 [00:00<00:00, 1.67MB/s]\n",
      "pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 510M/510M [00:10<00:00, 50.8MB/s]\n",
      "/home/ana/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('pierreguillou/gpt2-small-portuguese')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('pierreguillou/gpt2-small-portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a5d018-7c7b-4170-80a8-8b9fc88d5c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:07:45.395964Z",
     "iopub.status.busy": "2024-02-19T23:07:45.395386Z",
     "iopub.status.idle": "2024-02-19T23:07:47.428924Z",
     "shell.execute_reply": "2024-02-19T23:07:47.428544Z",
     "shell.execute_reply.started": "2024-02-19T23:07:45.395943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████| 1485/1485 [00:00<00:00, 2834.13 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 367/367 [00:00<00:00, 2197.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the dataset\n",
    "# https://huggingface.co/docs/transformers/en/pad_truncation\n",
    "def encode(examples):\n",
    "    encoded = tokenizer(examples['page'],\n",
    "                        truncation=True, \n",
    "                        padding='max_length',\n",
    "                        max_length=128\n",
    "                       )\n",
    "    encoded['labels'] = encoded['input_ids'][:]\n",
    "\n",
    "    return encoded\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce47ca9-fc19-47e4-b5c6-b0ba4434bf4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T22:46:09.102739Z",
     "iopub.status.busy": "2024-02-05T22:46:09.102005Z",
     "iopub.status.idle": "2024-02-05T22:46:09.143052Z",
     "shell.execute_reply": "2024-02-05T22:46:09.141608Z",
     "shell.execute_reply.started": "2024-02-05T22:46:09.102656Z"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5701cff-502c-4f7a-8b62-c4f6e50d10be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:08:27.057452Z",
     "iopub.status.busy": "2024-02-19T23:08:27.057199Z",
     "iopub.status.idle": "2024-02-19T23:08:27.082117Z",
     "shell.execute_reply": "2024-02-19T23:08:27.081575Z",
     "shell.execute_reply.started": "2024-02-19T23:08:27.057431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=tempfile.mkdtemp(),   # output directory\n",
    "    num_train_epochs=10,             # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,                # directory for storing logs\n",
    "    fp16=True                        # use floating point 16 bit precision for training\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a83c7-68e0-4c1f-a87a-069d1984ba0f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475c96de-a395-4374-b9cb-0461de41f29b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:08:27.617440Z",
     "iopub.status.busy": "2024-02-19T23:08:27.617095Z",
     "iopub.status.idle": "2024-02-19T23:08:29.241787Z",
     "shell.execute_reply": "2024-02-19T23:08:29.241289Z",
     "shell.execute_reply.started": "2024-02-19T23:08:27.617421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate before fine-tuning\n",
    "pre_eval_results = trainer.evaluate(encoded_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49120df5-53e2-486d-8888-f4abb706a45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:08:29.242714Z",
     "iopub.status.busy": "2024-02-19T23:08:29.242581Z",
     "iopub.status.idle": "2024-02-19T23:08:29.394841Z",
     "shell.execute_reply": "2024-02-19T23:08:29.394351Z",
     "shell.execute_reply.started": "2024-02-19T23:08:29.242700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61aefb-33e7-4ad9-9ff9-9966a9ce9a17",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9630696a-6adc-45f5-8e5c-131a7fccf1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:08:29.395614Z",
     "iopub.status.busy": "2024-02-19T23:08:29.395455Z",
     "iopub.status.idle": "2024-02-19T23:13:03.373766Z",
     "shell.execute_reply": "2024-02-19T23:13:03.373407Z",
     "shell.execute_reply.started": "2024-02-19T23:08:29.395599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1860' max='1860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1860/1860 04:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.967100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.757100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1860, training_loss=0.9571244598716818, metrics={'train_runtime': 273.8264, 'train_samples_per_second': 54.231, 'train_steps_per_second': 6.793, 'total_flos': 970046668800000.0, 'train_loss': 0.9571244598716818, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e96b2c8-f881-46c4-91ae-4ca4517be7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T23:14:41.026390Z",
     "iopub.status.busy": "2024-02-19T23:14:41.025914Z",
     "iopub.status.idle": "2024-02-19T23:14:41.351643Z",
     "shell.execute_reply": "2024-02-19T23:14:41.350934Z",
     "shell.execute_reply.started": "2024-02-19T23:14:41.026373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 780.00 MiB (GPU 0; 5.80 GiB total capacity; 3.86 GiB already allocated; 324.75 MiB free; 4.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pre_val_predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(encoded_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate after fine-tuning\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m post_eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print the evaluation losses before and after fine-tuning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation Results before fine-tuning :\u001b[39m\u001b[38;5;124m'\u001b[39m, pre_eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:3095\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3092\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3094\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3095\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3098\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3099\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3105\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:3284\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3283\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3284\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3285\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3286\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:3501\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3500\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3501\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3502\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:817\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:805\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:817\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:805\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: ConvertOutputsToFp32.__call__ at line 805 (1 times), autocast_decorator.<locals>.decorate_autocast at line 14 (1 times), convert_outputs_to_fp32.<locals>.forward at line 817 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:817\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/accelerate/utils/operations.py:805\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1107\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# Flatten the tokens\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1107\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshift_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1110\u001b[0m     output \u001b[38;5;241m=\u001b[39m (lm_logits,) \u001b[38;5;241m+\u001b[39m transformer_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/volupal_delete/ElevaQ/env/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 780.00 MiB (GPU 0; 5.80 GiB total capacity; 3.86 GiB already allocated; 324.75 MiB free; 4.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(1)))\n",
    "# Evaluate after fine-tuning\n",
    "post_eval_results = trainer.evaluate(encoded_dataset['test'])\n",
    "\n",
    "# Print the evaluation losses before and after fine-tuning\n",
    "print('Evaluation Results before fine-tuning :', pre_eval_results['eval_loss'])\n",
    "print('Evaluation Results after fine-tuning  :', post_eval_results['eval_loss'])\n",
    "\n",
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "post_val_predictions = trainer.predict(encoded_dataset['test'].select(range(1)))\n",
    "\n",
    "# Zip the pre and post tuning predictions\n",
    "predictions = zip(pre_val_predictions.predictions, post_val_predictions.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984c0ea-a0e2-47ad-9344-c66534713d71",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3721cb-c26c-46af-a085-27714c9b19fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T23:13:04.204807Z",
     "iopub.status.idle": "2024-02-19T23:13:04.204983Z",
     "shell.execute_reply": "2024-02-19T23:13:04.204912Z",
     "shell.execute_reply.started": "2024-02-19T23:13:04.204903Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, (pre, post) in enumerate(predictions):\n",
    "    pre_pred = tokenizer.decode(np.argmax(pre, axis=-1), skip_special_tokens=True)\n",
    "    post_pred = tokenizer.decode(np.argmax(post, axis=-1), skip_special_tokens=True)\n",
    "    ground_truth = encoded_dataset['test'][idx][\"page\"]\n",
    "    \n",
    "    print(f'Ground truth {idx} \\n' + ground_truth + '\\n')\n",
    "    print('Pre-prediction \\n' + \"\".join(pre_pred) + '\\n')\n",
    "    print('Post-prediction \\n'+ \"\".join(post_pred) + '\\n')\n",
    "    print('----------------------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4a247-ebcc-40a1-b843-37d492df9652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
